{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17ee10-f51c-4bc7-b698-510cfda3747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149a398-b9df-4fe9-bcf7-d480a89389e0",
   "metadata": {},
   "source": [
    "Before we start:\n",
    "- Validation vs. Test\n",
    "- Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4a4e0-f213-476d-9a4d-cfb30c0b5ca7",
   "metadata": {},
   "source": [
    "Today we are going to talk about **Classification**. The goal will be to classify each observation into one of potentially many classes. We'll start with *binary* classification, or classifying into one of two classes. The following data can be found [here](https://www.kaggle.com/faressayah/college-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064cf4f4-fe03-4c0f-bbee-6ced9042730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we classify colleges as public or private?\n",
    "# let's look at a sample of 500 colleges\n",
    "df_college = pd.read_csv('data/college_data.csv').sample(n=200, random_state=2022).reset_index(drop=True)\n",
    "# what does random_state do?\n",
    "df_college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7277fb-8f6f-4d3d-aabe-28a1aea2b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the variable is_private!\n",
    "df_college['is_private'] = df_college['private'].apply(lambda x: int(x == 'Yes'))\n",
    "df_college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b46079-a50c-410a-a0a8-d11bbb28ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does out of state tuition predict private/public?\n",
    "plt.scatter(x=df_college['room_board'], y=df_college['is_private'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a732f-a5cc-47a8-b1ac-029217a4b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression doesn't seem to be the best here...\n",
    "sns.lmplot(x='outstate', y='is_private', data=df_college)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dc755-5f1f-4f58-aea9-b7ca1ec57826",
   "metadata": {},
   "source": [
    "- Does binary data fit the assumptions from OLS regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b33ee-2ffd-4913-a889-60604e5a65d9",
   "metadata": {},
   "source": [
    "The goal here will to predict the *probability* that a given observation falls into the class defined by $1$. In other words given independent variable $X$ and target variable $Y$, we want to find $P(Y=1|X)$. Additionaly we want to do with the same *linear* framework as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73825c3-db9d-41ca-b55a-b36c635be276",
   "metadata": {},
   "source": [
    "So let's instead try to predict the **Odds** of an event occurring. In sports betting, odds are often used instead of probability:\n",
    "\n",
    "- \"The San Francisco Giants are a long shot, they have 10-1 odds of winning.\"\n",
    "- \"There's no way the San Francisco 49ers are going to lose, the betting odds are one to five!\"\n",
    "- \"Never tell me the odds.\" - Han Solo, *Star Wars*\n",
    "\n",
    "If a event has probability $p$ of occuring, then the odds of the event are\n",
    "\n",
    "$$\n",
    "Odds = \\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "- What is $p$ in the two sports examples above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5008396-f1b9-4db7-998a-f018549de1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "df_college = pd.read_csv('data/college_data.csv')\n",
    "df_college['is_private'] = df_college['private'].apply(lambda x: int(x == 'Yes'))\n",
    "\n",
    "df_college['outstate'].hist(bins=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7b23e-83d0-4322-9696-a9842f903536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of these bins let's count the number of private schools to estimate P(is_private=1|outstate)\n",
    "tuition_bins = pd.cut(df_college['outstate'], bins=12)\n",
    "ct = pd.crosstab(tuition_bins,df_college['is_private'])\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef06fc-6596-4450-93ff-21044f418c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct['freq'] = (ct[1] / (ct[0] + ct[1]))\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57387c6-3e4d-47b9-a0ad-2cb5629d92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the midpoints\n",
    "ct['midpoints'] = ct.index.to_series().apply(lambda x: x.mid)\n",
    "\n",
    "# plot the frequency\n",
    "plt.scatter(x=ct['midpoints'], y=ct['freq'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d715196-7f6f-44a1-ba68-d8919510d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the odds\n",
    "def odds(p):\n",
    "    if p < 1.0:\n",
    "        return (p / (1-p))\n",
    "    \n",
    "    # if the odds are \"infinite\" set a cap at 75\n",
    "    else:\n",
    "        return 75\n",
    "\n",
    "\n",
    "ct['odds'] = ct['freq'].apply(odds)\n",
    "\n",
    "# plot the odds\n",
    "plt.scatter(x=ct['midpoints'], y=ct['odds'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86285daa-bc01-4846-8597-10518156923d",
   "metadata": {},
   "source": [
    "Now the Odds here don't look very linear... But the *log* of the odds does.\n",
    "\n",
    "The number $e=2.718281828...$ is a special constant.\n",
    "- The rate of change of the function $f(x)=e^x$ is given by $f'(x)=e^x$.\n",
    "- We also have that $\\displaystyle \\lim_{n\\rightarrow\\infty} \\left(1+ \\frac{1}{n}\\right)^n = e$ (related to compound interest)\n",
    "\n",
    "Consider\n",
    "$$\n",
    "y = f(x) = e^x.\n",
    "$$\n",
    "This completely determines the inverse relationship, i.e. the function $x=g(y)$:\n",
    "$$\n",
    "\\ln(y) = \\log_e(y) = \\log(y) = x\n",
    "$$\n",
    "\n",
    "Below we plot $\\displaystyle \\log\\left(\\frac{p}{1-p}\\right)$ against the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a117754-67cc-45bd-8275-f34f7ba11931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks a bit linear!\n",
    "ct['log_odds'] = ct['odds'].apply(lambda x : math.log(x))\n",
    "\n",
    "# plot the odds\n",
    "plt.scatter(x=ct['midpoints'], y=ct['log_odds'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc9b0e-d6b7-4afb-9a04-30e20f5614ab",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Find the parameters $\\beta_0, \\beta_1$ to create the model\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X\n",
    "$$\n",
    "\n",
    "Rearranging we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{p}{1-p} &= e^{\\beta_0 +\\beta_1 X}\\\\\n",
    "1 + \\frac{p}{1-p} &= 1 + e^{\\beta_0 +\\beta_1 X}\\\\\n",
    "\\frac{1}{1-p} &= 1 + e^{\\beta_0 +\\beta_1 X}\\\\\n",
    "1-p &= \\frac{1}{1 + e^{\\beta_0 +\\beta_1 X}}\\\\\n",
    "1 - \\frac{1}{1 + e^{\\beta_0 +\\beta_1 X}} &= p\\\\\n",
    "\\frac{ e^{\\beta_0 +\\beta_1 X}}{1 + e^{\\beta_0 +\\beta_1 X}} &= p\\\\\n",
    "\\frac{1}{ e^{-(\\beta_0 +\\beta_1 X)} + 1} &= p\\\\\n",
    "p(X) &= \\frac{1}{1 + e^{-(\\beta_0 +\\beta_1 X)}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927eda7-9f63-4271-bcca-cb96418b66f3",
   "metadata": {},
   "source": [
    "Thus performing linear regression on the log-odds is equivalent to fitting a logistic function to the data.\n",
    "- The function $p(x) = \\frac{1}{1+e^{-x}}$ is called a *sigmoid* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342b475-c5ef-4df0-bf6a-08483d8ce408",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 200)\n",
    "p = 1/(1 + np.exp(-x))\n",
    "plt.plot(x, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32069c80-e9cb-4342-8ace-d213ad167ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_college['outstate'], y=df_college['is_private'])\n",
    "\n",
    "# logistic model\n",
    "x = np.linspace(0, 20000, 10000)\n",
    "p = 1/(1 + np.exp(-((1/1000)*x-8)))\n",
    "plt.plot(x, p)\n",
    "plt.show()\n",
    "\n",
    "# scatter plot\n",
    "plt.scatter(x=ct['midpoints'], y=ct['freq'])\n",
    "plt.plot(x, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf68fa-8e9e-4c33-95e5-5e00894a0ca7",
   "metadata": {},
   "source": [
    "You can see here that the logistic model is estimating the probability values of the target variable with respect to the input variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bcabe4-280c-42af-b4ba-243f92a49e1f",
   "metadata": {},
   "source": [
    "- What is missing here before we can fit the model?\n",
    "\n",
    "### Likelihood\n",
    "\n",
    "- For our probability function and an observation $(x_i, y_i)$: What is the likelihood of $(x_i, y_i)$ occuring with the probability function $p(X)$?\n",
    "- Note here $y_i = 0$ OR $y_i = 1$.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\beta_0, \\beta_1) = p(x_i)^{y_i}(1-p(x_i))^{1-y_i}\n",
    "$$\n",
    "\n",
    "- We want to maximize the likelihood function!\n",
    "- This is equivalent to maximizing the **log-likelihood** function:\n",
    "\n",
    "$$\n",
    "\\mathcal{l}(\\beta_0, \\beta_1) = \\log(p(x_i)^{y_i}(1-p(x_i))^{1-y_i}) = y_i\\log(p(x_i)) + (1-y_i)\\log(1-p(x_i))\n",
    "$$\n",
    "\n",
    "In turn this is equivalent to *minimizing* the negative log-likelihood function:\n",
    "\n",
    "$$\n",
    "-\\mathcal{l}(\\beta_0, \\beta_1) = -y_i\\log(p(\\beta_0, \\beta_1, x_i))) - (1-y_i)\\log(1-p(\\beta_0, \\beta_1, x_i)\n",
    "$$\n",
    "\n",
    "- Note the inclusion of $\\beta_0, \\beta_1$ in the $p$ function.\n",
    "\n",
    "For many observations we arrive at\n",
    "\n",
    "$$\n",
    "-\\mathcal{l}(\\beta_0, \\beta_1) = \\sum_{i=1}^N -y_i\\log(p(\\beta_0, \\beta_1, x_i))) - (1-y_i)\\log(1-p(\\beta_0, \\beta_1, x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9ee59-90fa-4119-ac66-f18ab80c8e34",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Given $N$ data points $(x_i, y_i)$, find parameters $\\beta_0, \\beta_1$ for the model\n",
    "$$\n",
    "p(X) = \\frac{1}{1 + e^{-(\\beta_0 +\\beta_1 X)}}\n",
    "$$\n",
    "that minimize the loss function\n",
    "$$\n",
    "L(\\beta_0,\\beta_1) = -\\left(\\sum_{i=1}^N y_i\\log(p) + (1-y_i)\\log(1-p)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb5c761-f0c8-4478-ae0b-46744e49b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import logit\n",
    "\n",
    "model = logit(formula = 'is_private ~ outstate', data=df_college)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb4919a-41c9-475f-b30f-5257fc61a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "b0, b1 = res.params\n",
    "\n",
    "# plot the model against the 0-1 values\n",
    "plt.scatter(x=df_college['outstate'], y=df_college['is_private'])\n",
    "\n",
    "x = np.linspace(0, 20000, 10000)\n",
    "p = 1/(1 + np.exp(-(b1*x+b0)))\n",
    "plt.plot(x, p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c018d5-972e-4da6-8174-230092566a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model against the estimated probabilities\n",
    "plt.scatter(x=ct['midpoints'], y=ct['freq'])\n",
    "plt.plot(x, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc8cb1-047e-47af-95e8-1b16373f117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use seaborn's lmplot again\n",
    "sns.lmplot(x=\"outstate\", logistic=True, y=\"is_private\", data=df_college)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04034022-997f-445d-8284-4c8f312367b2",
   "metadata": {},
   "source": [
    "### Classification Metrics\n",
    "- How do we turn our probability prediction into a binary prediction?\n",
    "- What does it mean to set a *threshold* of 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f07dc4-da11-410b-bc49-f8a9847c49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_college['outstate']\n",
    "y = df_college['is_private']\n",
    "\n",
    "y_pred_prob = res.predict(x)\n",
    "y_pred_prob[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acd4e5-359c-4c8c-8cac-8028c2cf98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_prob >= 0.5).apply(int)\n",
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a60404-a54c-4be1-8398-8bd015f3b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's utilize sklearn's metrics package\n",
    "from sklearn import metrics\n",
    "\n",
    "acc = metrics.accuracy_score(y, y_pred)\n",
    "print(f'The Accuracy of this model is {100*acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9631c60-0863-4f9f-a575-32c7f5b5cfc5",
   "metadata": {},
   "source": [
    "Looks good... but how good is this really?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb860c3b-fc88-478b-8345-0635a0a212d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_ones = np.ones(len(y))\n",
    "\n",
    "acc = metrics.accuracy_score(y, y_all_ones)\n",
    "print(f'The Accuracy of always predicting private is {100*acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3276d22-6fba-4959-91d1-d2f5457e78b1",
   "metadata": {},
   "source": [
    "This is what we call an *imbalanced* dataset. There is not an even 50/50 split of private and public schools. To get a better idea of how our model is performing we can look at the **Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d9518-ee7d-4016-a2d3-7f1bc03da4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the confusion matrix\n",
    "cm = metrics.confusion_matrix(y, y_pred)\n",
    "# display it nicely\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ef682-6502-49eb-990f-905d0bd414e9",
   "metadata": {},
   "source": [
    "The bottom left corner are the number of False Positives and the top right corner are the number of False Negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b43e1-3a89-4cad-9966-50531a3db614",
   "metadata": {},
   "source": [
    "- The **Precision** measures how much we can trust the model's prediction of class 1:\n",
    "\n",
    "$$\n",
    "\\text{Precision }= \\frac{True Positives}{All Predicted Positives}\n",
    "$$\n",
    "\n",
    "- The **Recall** measures how well the model \"finds\" all of class 1:\n",
    "\n",
    "$$\n",
    "\\text{Precision }= \\frac{True Positives}{Total Positives}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ced214-dd90-4bfe-b7f5-12214ed5f8ca",
   "metadata": {},
   "source": [
    "What is the Precision and Recall above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4e628c-c5ce-4a31-a6f6-4934bb0ae7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = metrics.recall_score(y, y_pred)\n",
    "prec = metrics.precision_score(y, y_pred)\n",
    "\n",
    "print(f'The Recall of this model is {recall}')\n",
    "print(f'The Precision of this model is {prec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8701e4-bdfd-4d2c-b4e9-0c57aceabf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = metrics.recall_score(y, y_all_ones)\n",
    "prec = metrics.precision_score(y, y_all_ones)\n",
    "\n",
    "print(f'The Recall of the all ones model is {recall}')\n",
    "print(f'The Precision of the all ones model is {prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ae3a1-b76e-48df-b3dc-a647eff70756",
   "metadata": {},
   "source": [
    "- Will changing the threshold of class 1 change the precision, recall, and accuracy?\n",
    "\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/3/36/ROC_space-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c770a97-04ed-4210-a88d-d44d7af32e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the probability predictions to get the FPR and TPR for different thresholds\n",
    "FPR, TPR, thresholds = metrics.roc_curve(y, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29d1a5-2fb1-42bb-9fe4-8f52a9a77e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[:10], thresholds[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d888e50-97db-4f0c-bca7-6b707d49db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does this make sense? Why?\n",
    "FPR[:10], FPR[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f05be-4507-4be2-866d-56472ddf4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FPR, TPR)\n",
    "plt.title('Receiver Operating Charactertistic Curve (ROC)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1924d8-1ff7-4698-92b8-a4d0c5f3deb7",
   "metadata": {},
   "source": [
    "To get a single value, people often use the **A**rea **U**nder the **C**urve (AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f7090-3fad-45c9-8685-f1a51546cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(y, y_pred_prob)\n",
    "print(f'The AUC of this model is {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292398d-0c04-4459-9c2e-6627547800b9",
   "metadata": {},
   "source": [
    "- What is the AUC of randomly guessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21e81c-a512-490a-8e82-b3e9548abef3",
   "metadata": {},
   "source": [
    "### Multiple independent variables\n",
    "\n",
    "- Generalized Linear Models\n",
    "\n",
    "**Example (2 indep.):**\n",
    "\n",
    "Given $N$ data points $((x_1)_i, (x_2)_i, y_i)$, find parameters $\\beta_0, \\beta_1, \\beta_2$ for the model\n",
    "$$\n",
    "p(X) = \\frac{1}{1 + e^{-(\\beta_0 +\\beta_1 X_1 + \\beta_2 X_2)}}\n",
    "$$\n",
    "that minimize the loss function\n",
    "$$\n",
    "L(\\beta_0,\\beta_1, \\beta_2) = -\\left(\\sum_{i=1}^N y_i\\log(p) + (1-y_i)\\log(1-p)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5568c52-c6b9-4f9c-a7f3-0f5da3028df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logit(formula = 'is_private ~ outstate + s_f_ratio', data=df_college)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108dcb7-1e1d-42ee-8c89-24c9e5dab3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='outstate', y = 's_f_ratio', hue='is_private', data=df_college)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b4127-dd1d-4b7a-b587-b5ec535e587a",
   "metadata": {},
   "source": [
    "The **Decision Boundary** is the boundary between the model predicting class 0 and class 1\n",
    "\n",
    "$$\n",
    "p(X) = \\frac{1}{1 + e^{-(\\beta_0 +\\beta_1 X_1 + \\beta_2 X_2)}}=0.5\n",
    "$$\n",
    "\n",
    "equivalent to\n",
    "\n",
    "$$\n",
    "\\beta_0 +\\beta_1 X_1 + \\beta_2 X_2 = 0\\\\\n",
    "X_2 = -\\frac{\\beta_1}{\\beta_2}X_1 - \\frac{\\beta_0}{\\beta_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c23ff1-484b-4dba-bd39-e5b18f1e1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='outstate', y = 's_f_ratio', hue='is_private', data=df_college)\n",
    "\n",
    "b0, b1, b2 = res.params\n",
    "plt.axline((0,-b0/b2), slope=(-b1/b2), color='green', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01434c-174e-42fd-bfaa-9f5d0eae7923",
   "metadata": {},
   "source": [
    "Let's what we learned about validation sets to evaluate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe0aaf-29ed-4f45-bf17-94b688291f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df_college, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0a8df-49b3-44a7-b228-d46e632e9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logit(formula = 'is_private ~ outstate + s_f_ratio', data=train)\n",
    "res = model.fit()\n",
    "\n",
    "x = val[['outstate', 's_f_ratio']]\n",
    "y = val['is_private']\n",
    "\n",
    "y_pred_prob = res.predict(x)\n",
    "y_pred = (y_pred_prob >= 0.5).apply(int)\n",
    "\n",
    "acc = metrics.accuracy_score(y, y_pred)\n",
    "recall = metrics.recall_score(y, y_pred)\n",
    "prec = metrics.precision_score(y, y_pred)\n",
    "\n",
    "print(f'The Accuracy of the model on the validation set is {acc}')\n",
    "print(f'The Recall of the model on the validation set is {recall}')\n",
    "print(f'The Precision of the model on the validation set is {prec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4838099-e20b-4923-8ca0-eea1fad01fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train[['outstate', 's_f_ratio']]\n",
    "y = train['is_private']\n",
    "\n",
    "y_pred_prob = res.predict(x)\n",
    "y_pred = (y_pred_prob >= 0.5).apply(int)\n",
    "\n",
    "acc = metrics.accuracy_score(y, y_pred)\n",
    "recall = metrics.recall_score(y, y_pred)\n",
    "prec = metrics.precision_score(y, y_pred)\n",
    "\n",
    "print(f'The Accuracy of the model on the train set is {acc}')\n",
    "print(f'The Recall of the model on the train set is {recall}')\n",
    "print(f'The Precision of the model on the train set is {prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53d7d6-d16d-4aeb-bd82-55e523f2aded",
   "metadata": {},
   "source": [
    "### Imbalanced Classification\n",
    "\n",
    "Recall that this dataset is *imbalanced* meaning that there are more class 1 than class 0 datapoints.\n",
    "- Why might this cause issues during model development?\n",
    "- What if there are differences between class balance from train to validation to test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10cf57-964e-4b51-8488-c69d8a3a009a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train['is_private']) / len(train), sum(val['is_private']) / len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402bdbb-c430-4428-abb4-7cbd193ca955",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df_college, test_size=0.1, stratify=df_college[['is_private']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac4015-60d8-48ac-8f30-c53605a9d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(train['is_private']) / len(train), sum(val['is_private']) / len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69043011-ce46-454b-8793-5bdaf1bc5ba8",
   "metadata": {},
   "source": [
    "Some Techniques\n",
    "- Under/Over-sampling\n",
    "- Weighting the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461e19b-3e91-4795-881a-0e797ff17f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_college['is_private']), sum(-((df_college['is_private'])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ba4c2-aef4-40ed-8365-607f5815fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_college.sort_values('is_private').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb924ca-bc24-4736-adc7-458944e57304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# under-sample\n",
    "df_public = df_college.sort_values('is_private')[:200]\n",
    "df_private = df_college.sort_values('is_private')[-200:]\n",
    "df = pd.concat((df_public, df_private))\n",
    "\n",
    "sum(df['is_private']), sum(-((df['is_private'])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6b263-50ca-4412-816d-d2a86d0709b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over-sample\n",
    "df_public = df_college.sort_values('is_private')[:200]\n",
    "df = pd.concat((df_college, df_public))\n",
    "\n",
    "sum(df['is_private']), sum(-((df['is_private'])-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f0070-905d-42a5-a75e-0c3dae452ed3",
   "metadata": {},
   "source": [
    "Let $w_i$ be the positive example weight\n",
    "\n",
    "$$\n",
    "L(\\beta_0,\\beta_1, \\beta_2) = -\\left(\\sum_{i=1}^N w_i y_i\\log(p) + (1-y_i)\\log(1-p)\\right)\n",
    "$$\n",
    "\n",
    "- What happens if $0 < w_i < 1$ or if $w_i > 1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb724172-7026-426e-b8b0-1697a58ea7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = df_college[['outstate', 's_f_ratio']]\n",
    "y = df_college['is_private']\n",
    "\n",
    "model = LogisticRegression(class_weight={0: 1.0, 1: 100.0}, max_iter=400)\n",
    "model.fit(x,y)\n",
    "\n",
    "# 0,1 predictions\n",
    "y_pred = model.predict(x)\n",
    "\n",
    "# probability outputs\n",
    "y_pred_prob = model.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710ecf0-9c7e-4710-9198-791c7e578e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10], y_pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5865ac-721f-4fb3-8ad1-eb9c165306d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(y, y_pred)\n",
    "recall = metrics.recall_score(y, y_pred)\n",
    "prec = metrics.precision_score(y, y_pred)\n",
    "\n",
    "print(f'The Accuracy of the model is {acc}')\n",
    "print(f'The Recall of the model is {recall}')\n",
    "print(f'The Precision of the model is {prec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea9d89-622f-4bd2-a39a-8054a245bbfb",
   "metadata": {},
   "source": [
    "Quiz3 Next Week:\n",
    "- Summary Above\n",
    "- Classification Metrics\n",
    "- Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e7469-d856-4635-962c-78dfe4c54708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
